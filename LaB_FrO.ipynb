{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-resident",
   "metadata": {},
   "source": [
    "# __PROBLEMA BUS DI SUPPORTO COVID__\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## Testo del problema \n",
    "\n",
    "Produrre un notebook con il codice che, \n",
    "dato un numero di autobus aggiuntivi, \n",
    "determina le sequenze di porzioni di viaggio da affidare a ciascun veicolo e massimizza il numero di passeggeri raccolti. \n",
    "Una porzione di viaggio può essere assegnata ad al massimo un veicolo. \n",
    "Analizzare il valore della funzione obiettivo al variare del numero di autobus aggiuntivi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-floating",
   "metadata": {},
   "source": [
    "### Pacchetti aggiuntivi utilizzati\n",
    "\n",
    "\n",
    "* [pandas](https://pandas.pydata.org/docs/index.html)\n",
    "* [openpyxl](https://openpyxl.readthedocs.io/en/stable/)\n",
    "* [numpy](https://numpy.org/)\n",
    "* [datetime](https://docs.python.org/3/library/datetime.html)\n",
    "* [networkx](https://networkx.org/documentation/stable/)\n",
    "* [matplotlib.pyplot](https://matplotlib.org/stable/users/index.html)\n",
    "* [seaborn](https://seaborn.pydata.org/introduction.html)\n",
    "\n",
    "    Importiamo le librerie in questione e per semplicità le denominiamo con delle sigle.  \n",
    "    Questo ci consente di richiamare i moduli e le sue funzioni citando solamente la sigla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-pencil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl as opx\n",
    "import numpy as np\n",
    "from datetime import date, datetime, time, timedelta\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-concord",
   "metadata": {},
   "source": [
    "### Scelta file\n",
    "\n",
    "Vista l'ambiguità delle date nel file fornito abbiamo deciso di dare all'utente la possibilità di scegliere se usare lo stesso oppure un file modificato da noi contenente le stesse informazioni condensate nello stesso giorno. Le soluzioni saranno ovviamente differenti a seconda del file scelto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "risp = False\n",
    "while (risp == False):\n",
    "    ans = input('Quale file si vuole utilizzare?\\n\\n1 = File Originale\\n\\n2 = File modificato con porzioni di viaggio tutte nella stessa data\\n\\nDigitare il numero dell\\'opzione   ')\n",
    "    if (ans == '1' or ans == '2'):\n",
    "        risp = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-myanmar",
   "metadata": {},
   "source": [
    "### Inserire su python i parametri presenti sul file selezionato\n",
    "   \n",
    "   > [file di dati](./file%20di%20dati.xlsx)\n",
    "   \n",
    "   > [file di dati singolo giorno](./file%20di%20dati%20singolo%20giorno.xlsx)\n",
    "   \n",
    "\n",
    "Per fare questo, ci serviamo delle librerie _PANDAS_ e _OPENPYXL_ la quale consentono l'importazione di tabelle da excel e in seguito l'importazione di questi in una struttura di dati con la funzione `DataFrame()`\n",
    "\n",
    "La scelta di utilizzare `DataFrame()` è stata dettata da una migliore possibilità di gestione dei dati e visualizzazione\n",
    "\n",
    "Con l'utilizzo di _Openpyxl_, importiamo le tabelle del foglio excel selezionato.\n",
    "\n",
    "In particolare: \n",
    "\n",
    ">__tratte__ sarà una lista di liste contenente i dati presenti sul foglio \"porzioni di viaggio\" del file \n",
    " \n",
    ">__tempi__ sarà una seconda lista di liste contenente i dati presenti nel foglio \"tempi di percorrenza a vuoto\" dello stesso file\n",
    " \n",
    "Una volta importati i dati, generiamo dei DataFrame ovvero delle strutture dati ordinate contenenti le medesime informazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ans == '1':\n",
    "    file = 'file di dati.xlsx'\n",
    "else:\n",
    "    file = 'file di dati singolo giorno.xlsx'\n",
    "\n",
    "xlsx   = opx.load_workbook(filename = file, data_only=True)\n",
    "tratte = xlsx['porzioni di viaggio']\n",
    "tempi  = xlsx['tempi di percorrenza a vuoto']\n",
    "\n",
    "df_tempi    = pd.DataFrame(np.array([[i.value for i in j] for j in  tempi['A2':'Q18']]))  \n",
    "df_porzioni = pd.DataFrame(np.array([[i.value for i in j] for j in tratte['A2':'F158']])) \n",
    "\n",
    "xlsx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-basketball",
   "metadata": {},
   "source": [
    "### L'utente sceglie il numero massimo di autobus aggiuntivi\n",
    " \n",
    " Ogni volta che viene eseguito il programma, esso richiederà di inserire:\n",
    "\n",
    ">`max_bus` : Numero massimo di autobus di supporto a disposizione del comune\n",
    "\n",
    "Conoscendo il numero massimo di autobus presenti nel deposito, calcoliamo il numero di passeggeri raccolti da ___k___ autobus, per ogni _k_ che va da _0_ a _max_bus_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-pathology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_bus = int(input(\"\\nINSERIRE il numero di autobus a disposizione del comune \\nIn seguito premere INVIO:\\n\\n\\n\"))\n",
    "\n",
    "K = set(range(1, max_bus + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-intent",
   "metadata": {},
   "source": [
    "## Formattiamo correttamente le tabelle importate\n",
    "\n",
    "### Formattazione tabella df_tempi\n",
    "\n",
    "Abbiamo corretto la formattazione \"grezza\" data dall'importazione delle tabelle.\n",
    "\n",
    "Per fare questo abbiamo:\n",
    "    \n",
    "1. creato un tipo _Series_ contenente i nomi delle fermate :   __ser_t__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_t = df_tempi.iloc[0:17, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-first",
   "metadata": {},
   "source": [
    "2. Sostituito gli indici vecchi delle tabelle con `ser_t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tempi.columns = ser_t\n",
    "df_tempi.index = ser_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-baseball",
   "metadata": {},
   "source": [
    "3. Abbiamo eliminato la riga e la colonna delle intestazioni vecchie dalla tabella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tempi.columns = df_tempi.columns.fillna('drop')\n",
    "df_tempi.index = df_tempi.index.fillna('drop')\n",
    "df_tempi.drop('drop', inplace = True)\n",
    "df_tempi.drop('drop', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-marsh",
   "metadata": {},
   "source": [
    "### Formattazione tabella df_porzioni\n",
    "\n",
    "Allo stesso modo abbiamo corretto la formattazione \"grezza\" anche del DataFrame delle porzioni di viaggio a vuoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_p = df_porzioni.iloc[0, 0:6]\n",
    "df_porzioni.columns = ser_p\n",
    "df_porzioni.drop( 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-palestine",
   "metadata": {},
   "source": [
    "### Ulteriore correzione alla tabella\n",
    "\n",
    "La nostra intenzione è quella di utilizzare i nomi delle stazioni per accedere ai dati delle due tabelle.\n",
    "Per fare questo e per confrontare le percorrenze, abbiamo la necessità che le stringhe contenenti i __NOMI DELLE STAZIONI__ siano uguali\n",
    "\n",
    "Per fare questo:\n",
    "    \n",
    "* abbiamo corretto i nomi presenti nelle colonne 'C' e 'D' della tabella __df_porzioni__ \n",
    "\n",
    "* abbiamo inoltre riscritto i nomi delle stazioni nella tabella __df_tempi__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, 156):\n",
    "    for j in range (2, 4):\n",
    "        if 'medag' in df_porzioni.iat[i, j]:\n",
    "            df_porzioni.iat[i, j] = \"medaglie d'oro\"\n",
    "        if ('stazione' in df_porzioni.iat[i, j] and df_porzioni.iat[i, j] != 'autostazione'):\n",
    "            df_porzioni.iat[i, j] = \"stazione\"\n",
    "        if 'kenn' in df_porzioni.iat[i, j]:\n",
    "            df_porzioni.iat[i, j] = \"kennedy\"\n",
    "        if 'medoro' in df_porzioni.iat[i, j]:\n",
    "            df_porzioni.iat[i, j] = \"corti di medoro\"\n",
    "        if 'pontegra' in df_porzioni.iat[i, j]:\n",
    "            df_porzioni.iat[i, j] = \"pontegradella itis\"\n",
    "        if 'smm' in df_porzioni.iat[i, j]:\n",
    "            df_porzioni.iat[i, j] = \"smm\"\n",
    "        else: continue\n",
    "            \n",
    "\n",
    "idx_list = df_tempi.index.tolist()\n",
    "idx = pd.Series(idx_list)\n",
    "idx[5] = \"medaglie d'oro\"\n",
    "idx = idx.replace({'stazione fs':'stazione', 'piazzale dante':'p. dante', 'santa maria maddalena': 'smm'})\n",
    "df_tempi.index = idx\n",
    "df_tempi.columns = idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-union",
   "metadata": {},
   "source": [
    "# SVOLGIMENTO DEL PROBLEMA\n",
    "\n",
    "Una volta corrette le importazioni delle due tabelle, passiamo alla risoluzione del problema.\n",
    "\n",
    "### Matrice di compatibilità\n",
    "Abbiamo generato una matrice __C__ definita di compatibilità:\n",
    "\n",
    "$\n",
    "c_{ij} =\\begin{cases} 1 & \\mbox{se le tratte i-j sono compatibili} \\\\ 0 & \\mbox{Altrimenti }\\end{cases}\n",
    "$\n",
    "\n",
    "Per valutare la compatibilità tra le tratte _i_ e _j_ dobbiamo verificare che, sommando all'orario di fine della tratta _i_ il tempo di percorrenza a vuoto da _i_ a _j_, si ottenga un orario antecedente all'orario di partenza della tratta _j_.\n",
    "\n",
    "In formule:\n",
    "\n",
    "$\n",
    "T_{\\mbox{fine lavoro bus supporto}} + T_{\\mbox{percorrenza a vuoto per arrivare alla nuova stazione}} \\leq T_{\\mbox{inizio nuovo lavoro di supporto}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.zeros((156, 156))\n",
    "I = set(range(1, 157))\n",
    "for i in I:\n",
    "    for j in I:\n",
    "        if df_porzioni.at[i, \"final stop\"] == df_porzioni.at[j, \"initial stop\"]:\n",
    "            continue\n",
    "        elif df_tempi.at[df_porzioni.at[i, \"final stop\"], df_porzioni.at[j, \"initial stop\"]] is None:\n",
    "                delta = df_tempi.at[df_porzioni.at[j, \"initial stop\"], df_porzioni.at[i, \"final stop\"]]\n",
    "        else:\n",
    "                delta = df_tempi.at[df_porzioni.at[i, \"final stop\"], df_porzioni.at[j, \"initial stop\"]]\n",
    "        \n",
    "        if (df_porzioni.at[i, \"final time\"] + timedelta(minutes = delta) <= df_porzioni.at[j, \"initial time\"]):\n",
    "            c[i-1, j-1] = 1\n",
    "        else :\n",
    "            c[i-1, j-1] = 0   \n",
    "\n",
    "C = pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-jimmy",
   "metadata": {},
   "source": [
    "### Passeggeri Extra\n",
    "\n",
    "Ora definiamo il _DataFrame_ __df_extra__ che presenta il numero di passeggeri che hanno bisogno di un autobus di supporto per ogni tratta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_pass = df_porzioni[\"extra passengers\"]\n",
    "df_extra = extra_pass.copy() \n",
    "tratte_bus = df_porzioni [['initial stop', 'final stop']]\n",
    "df_tratte = tratte_bus.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-swift",
   "metadata": {},
   "source": [
    "## Soluzione grafica\n",
    "\n",
    "Abbiamo affrontato il problema graficamente.\n",
    "\n",
    "Abbiamo generato un grafo avente i due nodi principali _POZZO_ e _SORGENTE_.<br>\n",
    "Ad essi abbiamo aggiunto due serie di nodi che rappresentano le tratte raffigurate nella tabella __df_porzioni__<br>\n",
    "I nodi della prima serie che chiameremo <ins>\"nodo 1\"</ins> sarà lato sorgente e collegata ad essa<br>\n",
    "I nodi della seconda serie <ins>\"nodo 2\"</ins> saranno collegata ai nodi primari delle tratte con cui la tratta che rappresentano è compatibile e al pozzo  \n",
    "\n",
    "__Abbiamo separato la stessa tratta in due nodi distinti perchè altrimenti più di un autobus si recherebbe nello stesso nodo per raccogliere i passeggeri, pur non essendo efettivamente assegnato alla tratta in questione.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./immagine_lab.PNG\" width =\"700\">\n",
    "<center>Per agevolare la comprensione della topologia del grafo abbiamo allegato un'immagine esemplificativa</center>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### Costruzione del Grafo\n",
    "\n",
    "Definiamo il grafo direzionale __G__ con la funzione `DiGraph()` della libreria _Networkx_. \n",
    "<br>\n",
    "\n",
    "Con la funzione `add_edge()` creiamo gli archi che collegano i nodi primari con i loro secondari.<br>In realtà, dato che i nodi $u_i$ e $v_i$ non esistono ancora, la stessa funzione li genera.<br>\n",
    "Gli archi in questione hanno:\n",
    "* Peso 0\n",
    "* Capacità 1 \n",
    "\n",
    "La capacità unitaria di questi archi garantisce che solamente un'unità di flusso(autobus) attraversi l'arco, poichè questi archi sono gli unici in uscita nei nodi primari, garantisce anche che sia una sola unità di flusso a passare per il nodo primario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in I:\n",
    "    u_i = '{}. {} -> {} nodo1'.format(i, df_tratte.at[i, 'initial stop'],df_tratte.at[i, 'final stop'])\n",
    "    v_i = '{}. {} -> {} nodo2'.format(i, df_tratte.at[i, 'initial stop'],df_tratte.at[i, 'final stop'])\n",
    "    G.add_edge(u_of_edge = u_i, v_of_edge = v_i, weight = 0, capacity = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-living",
   "metadata": {},
   "source": [
    "Il grafo ora inizializzato può essere così popolato:\n",
    "\n",
    "Se $c_{ij}$ = 1, viene aggiunto un arco avente\n",
    "\n",
    "* Peso pari all'opposto del numero di passeggeri extra nella tratta in questione \n",
    "* Capacità 1 \n",
    "\n",
    "\n",
    "Questi archi collegano, per ogni tratta, il nodo secondario al nodo primario di tutte le tratte ad esso compatibili.\n",
    "\n",
    "\n",
    "La motivazione legata al costo negativo di questi archi è data dal fatto che con questo metodo è possibile risolvere il grafo come un problema di<br> __flusso di costo minimo__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in I:\n",
    "    for j in I:\n",
    "        if c[i-1, j-1] == 1:\n",
    "            u_comp = '{}. {} -> {} nodo2'.format(i, df_tratte.at[i, 'initial stop'],df_tratte.at[i, 'final stop'])\n",
    "            v_comp = '{}. {} -> {} nodo1'.format(j, df_tratte.at[j, 'initial stop'],df_tratte.at[j, 'final stop'])\n",
    "            G.add_edge(u_of_edge = u_comp, v_of_edge = v_comp, weight = -df_extra[j] , capacity = 1)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-bangkok",
   "metadata": {},
   "source": [
    "Aggiungiamo in seguito i nodi:  \n",
    "* __s__  Sorgente  \n",
    "* __t__  Pozzo\n",
    "\n",
    "In seguito aggiungiamo tutti gli archi che dalla _sorgente_ vanno verso i nodi primari e tutti gli archi che dai nodi secondari vanno al _pozzo_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_node('s')\n",
    "G.add_node('t')\n",
    "for i in I:\n",
    "    u_i = '{}. {} -> {} nodo1'.format(i, df_tratte.at[i, 'initial stop'],df_tratte.at[i, 'final stop'])\n",
    "    v_i = '{}. {} -> {} nodo2'.format(i, df_tratte.at[i, 'initial stop'],df_tratte.at[i, 'final stop'])\n",
    "    G.add_edge(u_of_edge = 's', v_of_edge = u_i, weight = -df_extra[i], capacity = 1)\n",
    "    G.add_edge(u_of_edge = v_i, v_of_edge = 't', weight = 0, capacity = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-rwanda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Soluzione al problema\n",
    "\n",
    "Per ogni iterazione viene aggiunto l'arco che collega il _pozzo_ con la _sorgente_ avente:\n",
    "* Peso 0\n",
    "* Capacità __k__\n",
    "\n",
    "Questo arco permette di rispettare il vincolo sul numero di autobus.\n",
    "\n",
    "Avremmo potuto in modo equivalente aggiungere delle etichette ai nodi pozzo e sorgente, rispettivamente _-k_ e _k_\n",
    "\n",
    "Una volta completata la struttura viene calcolato il __FLUSSO DI COSTO MINIMO__ in funzione di _k_.\n",
    "\n",
    "__Al raggiungimento del numero di autobus necessari a raccogliere tutti i passeggeri possibili il programma termina.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_costs_k = []\n",
    "\n",
    "k = 0\n",
    "incremento = True\n",
    "while (incremento and k < max_bus):\n",
    "    G.add_edge(u_of_edge = 't', v_of_edge = 's', weight = 0, capacity = k)\n",
    "    flowCost, flowDict = nx.algorithms.flow.network_simplex(G, capacity ='capacity', weight ='weight')\n",
    "    flow_costs_k.append((-1)*flowCost)\n",
    "    \n",
    "    if (flow_costs_k[k] == flow_costs_k[k-1] and k > 1):\n",
    "        flow_max = flow_costs_k[k-1]\n",
    "        incremento = False\n",
    "    k = k + 1\n",
    "    \n",
    "if(incremento == False):\n",
    "    for i in range(3):\n",
    "        flow_costs_k.append(flow_max)\n",
    "\n",
    "flow_edges = []\n",
    "\n",
    "for u, v in G.edges():\n",
    "    G[u][v]['weight'] = -G[u][v]['weight']\n",
    "    if flowDict[u][v] != 0:\n",
    "        flow_edges.append(('%s'%u,'%s'%v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-aging",
   "metadata": {},
   "source": [
    "### Generazione istogramma \n",
    "Il problema conta e produce un istogramma che mostra il numero di passeggeri raccolti in funzione del numero _k_ di autobus impiegati.\n",
    "\n",
    "Grazie all'utilizzo della libreria _Seaborn_, con la funzione `catplot()` generiamo un istogramma\n",
    "\n",
    "Sull'asse delle x c'è il valore di __k__  \n",
    "Sull'asse delle y invece il numero di passeggeri trasportati\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_k = pd.Series(flow_costs_k)\n",
    "\n",
    "ser_k = pd.DataFrame(ser_k)\n",
    "ser_k = ser_k.transpose()\n",
    "plot = sbn.catplot(data =ser_k, kind =\"bar\", aspect = 2, height =10, palette =\"crest\")\n",
    "\n",
    "plot.savefig('Istogramma.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-frequency",
   "metadata": {},
   "source": [
    "Per praticità e migliore visualizzazione, abbiamo esportato la figura in file:\n",
    "\n",
    ">[Istogramma.png](./Istogramma.png)  \n",
    "    \n",
    "    Cliccando il link si può così vedere il risultato finale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
